{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script><script type=\"text/javascript\">if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script><script>requirejs.config({paths: { 'plotly': ['https://cdn.plot.ly/plotly-latest.min']},});if(!window._Plotly) {require(['plotly'],function(plotly) {window._Plotly=plotly;});}</script>"
      ],
      "text/vnd.plotly.v1+html": [
       "<script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script><script type=\"text/javascript\">if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script><script>requirejs.config({paths: { 'plotly': ['https://cdn.plot.ly/plotly-latest.min']},});if(!window._Plotly) {require(['plotly'],function(plotly) {window._Plotly=plotly;});}</script>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "from torch import nn\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import numpy as np\n",
    "from sklearn.cluster import KMeans\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import plotly.plotly as py\n",
    "import plotly\n",
    "import plotly.graph_objs as go\n",
    "from plotly.offline import download_plotlyjs, init_notebook_mode, plot, iplot\n",
    "\n",
    "init_notebook_mode(connected=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "location = './All_Data/Urban Local Bodies & Municipal Councils'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "inda = pd.read_csv(location + '/ULB1A.csv')\n",
    "indb = pd.read_csv(location + '/ULB1B.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5201 5225\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sreerag/.local/lib/python3.5/site-packages/ipykernel_launcher.py:33: DeprecationWarning:\n",
      "\n",
      "\n",
      ".ix is deprecated. Please use\n",
      ".loc for label based indexing or\n",
      ".iloc for positional indexing\n",
      "\n",
      "See the documentation here:\n",
      "http://pandas.pydata.org/pandas-docs/stable/indexing.html#ix-indexer-is-deprecated\n",
      "\n",
      "/home/sreerag/.local/lib/python3.5/site-packages/ipykernel_launcher.py:33: FutureWarning:\n",
      "\n",
      "Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5225 5225\n"
     ]
    }
   ],
   "source": [
    "\n",
    "hrs = list()\n",
    "hrs.append(1)\n",
    "for i in range(1, len(indb)):\n",
    "    hrs.append(round((indb['time'][i] - indb['time'][i - 1]) / (3600000) + hrs[i-1]))\n",
    "    \n",
    "indb['hrs'] = hrs\n",
    "\n",
    "hrs = list()\n",
    "hrs.append(1)\n",
    "for i in range(1, len(inda)):\n",
    "    hrs.append(round((inda['time'][i] - inda['time'][i - 1]) / (3600000) + hrs[i-1]))\n",
    "\n",
    "inda['hrs'] = hrs    \n",
    "\n",
    "j = 0\n",
    "m=len(indb)\n",
    "n=len(inda)\n",
    "print(len(indb),len(inda))\n",
    "for i in range(len(inda) - 1):\n",
    "    if (abs(inda['hrs'][i] - indb['hrs'][j]) != 0) and ((abs(inda['hrs'][i] - indb['hrs'][j])) == 2):\n",
    "        if(n>m):\n",
    "            line1 = pd.DataFrame({\"id\": -30, \"time\": -30, 'vol':-1, \n",
    "                             'ph': 1000, 'solids':1000, \n",
    "                              'hardness': 1000, 'oil': 1000,\n",
    "                              'bod': 1000, 'quality': 'dont know', 'hrs': inda['hrs'][i]}, index=[j])\n",
    "            line2 = pd.DataFrame({\"id\": -30, \"time\": -30, 'vol': -1, \n",
    "                             'ph':1000, 'solids': 1000, \n",
    "                              'hardness': 1000, 'oil': 1000,\n",
    "                              'bod': 1000, 'quality': 'dont know', \n",
    "                              'hrs': inda['hrs'][i+1]}, index=[j+1])\n",
    "        \n",
    "            indb = pd.concat([indb.ix[:j-1], line1, line2, indb.ix[j:]]).reset_index(drop=True)\n",
    "        \n",
    "    j += 1\n",
    "print(len(indb), len(inda))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "class autoencoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(autoencoder, self).__init__()\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Linear(1, 128),\n",
    "            nn.ReLU(True),\n",
    "            nn.Linear(128, 64),\n",
    "            nn.ReLU(True), nn.Linear(64, 12), nn.ReLU(True), nn.Linear(12, 3))\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(3, 12),\n",
    "            nn.ReLU(True),\n",
    "            nn.Linear(12, 64),\n",
    "            nn.ReLU(True),\n",
    "            nn.Linear(64, 128),\n",
    "            nn.ReLU(True),\n",
    "            nn.Linear(128, 1),\n",
    "            nn.Sigmoid())\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.encoder(x)\n",
    "        x = self.decoder(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5225 (5225,)\n",
      "epoch [1/100], loss:60822904832.0000\n",
      "epoch [2/100], loss:60822904832.0000\n",
      "epoch [3/100], loss:60822904832.0000\n",
      "epoch [4/100], loss:60822904832.0000\n",
      "epoch [5/100], loss:60822904832.0000\n",
      "epoch [6/100], loss:60822904832.0000\n",
      "epoch [7/100], loss:60822904832.0000\n",
      "epoch [8/100], loss:60822904832.0000\n",
      "epoch [9/100], loss:60822904832.0000\n",
      "epoch [10/100], loss:60822904832.0000\n",
      "epoch [11/100], loss:60822904832.0000\n",
      "epoch [12/100], loss:60822904832.0000\n",
      "epoch [13/100], loss:60822904832.0000\n",
      "epoch [14/100], loss:60822904832.0000\n",
      "epoch [15/100], loss:60822904832.0000\n",
      "epoch [16/100], loss:60822409216.0000\n",
      "epoch [17/100], loss:60822409216.0000\n",
      "epoch [18/100], loss:60822409216.0000\n",
      "epoch [19/100], loss:60822409216.0000\n",
      "epoch [20/100], loss:60822409216.0000\n",
      "epoch [21/100], loss:60822409216.0000\n",
      "epoch [22/100], loss:60822409216.0000\n",
      "epoch [23/100], loss:60822409216.0000\n",
      "epoch [24/100], loss:60822409216.0000\n",
      "epoch [25/100], loss:60822409216.0000\n",
      "epoch [26/100], loss:60822409216.0000\n",
      "epoch [27/100], loss:60822409216.0000\n",
      "epoch [28/100], loss:60822409216.0000\n",
      "epoch [29/100], loss:60822409216.0000\n",
      "epoch [30/100], loss:60822409216.0000\n",
      "epoch [31/100], loss:60822409216.0000\n",
      "epoch [32/100], loss:60822409216.0000\n",
      "epoch [33/100], loss:60822409216.0000\n",
      "epoch [34/100], loss:60822409216.0000\n",
      "epoch [35/100], loss:60822409216.0000\n",
      "epoch [36/100], loss:60822409216.0000\n",
      "epoch [37/100], loss:60822409216.0000\n",
      "epoch [38/100], loss:60822409216.0000\n",
      "epoch [39/100], loss:60822409216.0000\n",
      "epoch [40/100], loss:60822409216.0000\n",
      "epoch [41/100], loss:60822409216.0000\n",
      "epoch [42/100], loss:60822409216.0000\n",
      "epoch [43/100], loss:60822409216.0000\n",
      "epoch [44/100], loss:60822409216.0000\n",
      "epoch [45/100], loss:60822409216.0000\n",
      "epoch [46/100], loss:60822409216.0000\n",
      "epoch [47/100], loss:60822409216.0000\n",
      "epoch [48/100], loss:60822409216.0000\n",
      "epoch [49/100], loss:60822409216.0000\n",
      "epoch [50/100], loss:60822409216.0000\n",
      "epoch [51/100], loss:60822409216.0000\n",
      "epoch [52/100], loss:60822409216.0000\n",
      "epoch [53/100], loss:60822409216.0000\n",
      "epoch [54/100], loss:60822409216.0000\n",
      "epoch [55/100], loss:60822409216.0000\n",
      "epoch [56/100], loss:60822409216.0000\n",
      "epoch [57/100], loss:60822409216.0000\n",
      "epoch [58/100], loss:60822409216.0000\n",
      "epoch [59/100], loss:60822409216.0000\n",
      "epoch [60/100], loss:60822409216.0000\n",
      "epoch [61/100], loss:60822409216.0000\n",
      "epoch [62/100], loss:60822409216.0000\n",
      "epoch [63/100], loss:60822409216.0000\n",
      "epoch [64/100], loss:60822409216.0000\n",
      "epoch [65/100], loss:60822409216.0000\n",
      "epoch [66/100], loss:60822409216.0000\n",
      "epoch [67/100], loss:60822409216.0000\n",
      "epoch [68/100], loss:60822409216.0000\n",
      "epoch [69/100], loss:60822409216.0000\n",
      "epoch [70/100], loss:60822409216.0000\n",
      "epoch [71/100], loss:60822409216.0000\n",
      "epoch [72/100], loss:60822409216.0000\n",
      "epoch [73/100], loss:60822409216.0000\n",
      "epoch [74/100], loss:60822409216.0000\n",
      "epoch [75/100], loss:60822409216.0000\n",
      "epoch [76/100], loss:60822409216.0000\n",
      "epoch [77/100], loss:60822409216.0000\n",
      "epoch [78/100], loss:60822409216.0000\n",
      "epoch [79/100], loss:60822409216.0000\n",
      "epoch [80/100], loss:60822409216.0000\n",
      "epoch [81/100], loss:60822409216.0000\n",
      "epoch [82/100], loss:60822409216.0000\n",
      "epoch [83/100], loss:60822409216.0000\n",
      "epoch [84/100], loss:60822409216.0000\n",
      "epoch [85/100], loss:60822409216.0000\n",
      "epoch [86/100], loss:60822409216.0000\n",
      "epoch [87/100], loss:60822409216.0000\n",
      "epoch [88/100], loss:60822409216.0000\n",
      "epoch [89/100], loss:60822409216.0000\n",
      "epoch [90/100], loss:60822409216.0000\n",
      "epoch [91/100], loss:60822409216.0000\n",
      "epoch [92/100], loss:60822409216.0000\n",
      "epoch [93/100], loss:60822409216.0000\n",
      "epoch [94/100], loss:60822409216.0000\n",
      "epoch [95/100], loss:60822409216.0000\n",
      "epoch [96/100], loss:60822409216.0000\n",
      "epoch [97/100], loss:60822409216.0000\n",
      "epoch [98/100], loss:60822409216.0000\n",
      "epoch [99/100], loss:60822409216.0000\n",
      "epoch [100/100], loss:60822409216.0000\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 100\n",
    "batch_size = 2\n",
    "learning_rate = 1e-3\n",
    "print(len(indb),indb['vol'].shape)\n",
    "indbvol=np.array(indb['vol'])\n",
    "dataset=np.reshape(indbvol,(len(indbvol),1))\n",
    "#dataset = [[1],[2],[3],[4],[5],[6],[7],[8],[9],[10]]\n",
    "#dataset = (dataset - np.min(dataset))/(np.max(dataset) - np.min(dataset))\n",
    "dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "model = autoencoder()\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(\n",
    "    model.parameters(), lr=learning_rate, weight_decay=1e-5)\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    for data in dataloader:\n",
    "        data = data.float()\n",
    "        #print(data)\n",
    "        data = Variable(data)\n",
    "        # ===================forward=====================\n",
    "        output = model(data)\n",
    "        loss = criterion(output, data)\n",
    "        # ===================backward====================\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    # ===================log========================\n",
    "    print('epoch [{}/{}], loss:{:.4f}'\n",
    "          .format(epoch + 1, num_epochs, loss.data))\n",
    "    #if epoch % 10 == 0:\n",
    "    #    pic = to_img(output.cpu().data)\n",
    "    #    save_image(pic, './mlp_img/image_{}.png'.format(epoch))\n",
    "\n",
    "#torch.save(model.state_dict(), './sim_autoencoder.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), './sim_autoencoder.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'autoencoder.model'\n",
    "pickle.dump(model, open(filename, 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'collections.OrderedDict' object has no attribute 'predict'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-46-bfec1c439d2a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mloaded_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloaded_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindb\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'vol'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'collections.OrderedDict' object has no attribute 'predict'"
     ]
    }
   ],
   "source": [
    "loaded_model = pickle.load(open(filename, 'rb'))\n",
    "result = loaded_model.predict(indb['vol'][0])\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "\nFound no NVIDIA driver on your system. Please check that you\nhave an NVIDIA GPU and installed a driver from\nhttp://www.nvidia.com/Download/index.aspx",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-47-8842da40f796>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mtest_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mVariable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0mtest_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest_value\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mtest_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest_value\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.5/site-packages/torch/cuda/__init__.py\u001b[0m in \u001b[0;36m_lazy_init\u001b[0;34m()\u001b[0m\n\u001b[1;32m    159\u001b[0m         raise RuntimeError(\n\u001b[1;32m    160\u001b[0m             \"Cannot re-initialize CUDA in forked subprocess. \" + msg)\n\u001b[0;32m--> 161\u001b[0;31m     \u001b[0m_check_driver\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    162\u001b[0m     \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cuda_init\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    163\u001b[0m     \u001b[0m_cudart\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_load_cudart\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.5/site-packages/torch/cuda/__init__.py\u001b[0m in \u001b[0;36m_check_driver\u001b[0;34m()\u001b[0m\n\u001b[1;32m     80\u001b[0m \u001b[0mFound\u001b[0m \u001b[0mno\u001b[0m \u001b[0mNVIDIA\u001b[0m \u001b[0mdriver\u001b[0m \u001b[0mon\u001b[0m \u001b[0myour\u001b[0m \u001b[0msystem\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mPlease\u001b[0m \u001b[0mcheck\u001b[0m \u001b[0mthat\u001b[0m \u001b[0myou\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     81\u001b[0m \u001b[0mhave\u001b[0m \u001b[0man\u001b[0m \u001b[0mNVIDIA\u001b[0m \u001b[0mGPU\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0minstalled\u001b[0m \u001b[0ma\u001b[0m \u001b[0mdriver\u001b[0m \u001b[0;32mfrom\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 82\u001b[0;31m http://www.nvidia.com/Download/index.aspx\"\"\")\n\u001b[0m\u001b[1;32m     83\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m             \u001b[0;31m# TODO: directly link to the alternative bin that needs install\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAssertionError\u001b[0m: \nFound no NVIDIA driver on your system. Please check that you\nhave an NVIDIA GPU and installed a driver from\nhttp://www.nvidia.com/Download/index.aspx"
     ]
    }
   ],
   "source": [
    "model = torch.load('./sim_autoencoder.pth')\n",
    "data = np.array([indb['vol'][0],indb['vol'][1]])\n",
    "data = torch.from_numpy(data)\n",
    "\n",
    "test_value = Variable(data.cuda())\n",
    "test_value = test_value.float()\n",
    "test_value = test_value.unsqueeze(0)\n",
    "\n",
    "prediction = model(test_value)\n",
    "cpu_pred = prediction.cpu()\n",
    "result = cpu_pred.data.numpy()\n",
    "ynew = model.predict_classes(data)\n",
    "print(data)\n",
    "print(ynew)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
